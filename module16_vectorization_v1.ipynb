{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28367419",
   "metadata": {},
   "source": [
    "## Word Embedding or Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15a5c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import warnings as wr\n",
    "wr.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9938ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task 1: load Data\n",
    "def load_date(file_path):\n",
    "    df = pd.read_csv(file_path, header=None,\n",
    "                    encoding='latin-1', names=['target','id','date','meta','user','text']\n",
    "                    )\n",
    "    df['sentiment'] = df['target'].apply(lambda x: 'positive' if x==4 else 'negative')\n",
    "    return df\n",
    "\n",
    "file_path = \"E:/M60/nlp_dataset/sentiment140_v1.csv\"\n",
    "df = load_date(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb5b21d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>meta</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      meta  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "  sentiment  \n",
       "0  negative  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "4  negative  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af78c2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(910, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4614bb",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408ddabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Stopwords:\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "default_stopwords = set(stopwords.words('english'))\n",
    "# print Standards Stopwords\n",
    "print(\"Default Stopwords:\")\n",
    "print(sorted(default_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e418b74",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba1a4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prep_text(text):\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # print(\"Lowercase: \", text)\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Print (\"Remove Punctuation: \",text)\n",
    "    # Tokenize the words\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Print (\"Remove stopwords: \", text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e15a6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(clean_prep_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a79f3ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>meta</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>switchfoot httptwitpiccom2y1zl awww thats bumm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>negative</td>\n",
       "      <td>kenichan dived many times ball managed save 50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>negative</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>negative</td>\n",
       "      <td>nationwideclass behaving im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>4</td>\n",
       "      <td>1467901707</td>\n",
       "      <td>Mon Apr 06 22:43:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>weboword</td>\n",
       "      <td>@tothepc Did you check out http://www.weboword...</td>\n",
       "      <td>positive</td>\n",
       "      <td>tothepc check httpwwwwebowordcom arent diction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>4</td>\n",
       "      <td>1467901716</td>\n",
       "      <td>Mon Apr 06 22:43:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>meganfinley</td>\n",
       "      <td>Artistic affirmation from a drunk lady was kin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>artistic affirmation drunk lady kinda needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>4</td>\n",
       "      <td>1467901742</td>\n",
       "      <td>Mon Apr 06 22:43:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>konelli</td>\n",
       "      <td>@Honey3223  Honey goodnight I am up really ear...</td>\n",
       "      <td>positive</td>\n",
       "      <td>honey3223 honey goodnight really early morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>4</td>\n",
       "      <td>1468004484</td>\n",
       "      <td>Mon Apr 06 23:12:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>l_eau</td>\n",
       "      <td>@Jon_Favreau &amp;quot;never worked on a sequel&amp;qu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>jonfavreau quotnever worked sequelquot maybe t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>4</td>\n",
       "      <td>1468004505</td>\n",
       "      <td>Mon Apr 06 23:12:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>aquaticgal02</td>\n",
       "      <td>@socalgurl83 LOL nice, thanks for translating</td>\n",
       "      <td>positive</td>\n",
       "      <td>socalgurl83 lol nice thanks translating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target          id                          date      meta  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "..      ...         ...                           ...       ...   \n",
       "905       4  1467901707  Mon Apr 06 22:43:52 PDT 2009  NO_QUERY   \n",
       "906       4  1467901716  Mon Apr 06 22:43:53 PDT 2009  NO_QUERY   \n",
       "907       4  1467901742  Mon Apr 06 22:43:53 PDT 2009  NO_QUERY   \n",
       "908       4  1468004484  Mon Apr 06 23:12:59 PDT 2009  NO_QUERY   \n",
       "909       4  1468004505  Mon Apr 06 23:12:56 PDT 2009  NO_QUERY   \n",
       "\n",
       "                user                                               text  \\\n",
       "0    _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1      scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2           mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3            ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4             Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "..               ...                                                ...   \n",
       "905         weboword  @tothepc Did you check out http://www.weboword...   \n",
       "906      meganfinley  Artistic affirmation from a drunk lady was kin...   \n",
       "907          konelli  @Honey3223  Honey goodnight I am up really ear...   \n",
       "908            l_eau  @Jon_Favreau &quot;never worked on a sequel&qu...   \n",
       "909     aquaticgal02     @socalgurl83 LOL nice, thanks for translating    \n",
       "\n",
       "    sentiment                                       cleaned_text  \n",
       "0    negative  switchfoot httptwitpiccom2y1zl awww thats bumm...  \n",
       "1    negative  upset cant update facebook texting might cry r...  \n",
       "2    negative  kenichan dived many times ball managed save 50...  \n",
       "3    negative                   whole body feels itchy like fire  \n",
       "4    negative           nationwideclass behaving im mad cant see  \n",
       "..        ...                                                ...  \n",
       "905  positive  tothepc check httpwwwwebowordcom arent diction...  \n",
       "906  positive       artistic affirmation drunk lady kinda needed  \n",
       "907  positive  honey3223 honey goodnight really early morning...  \n",
       "908  positive  jonfavreau quotnever worked sequelquot maybe t...  \n",
       "909  positive            socalgurl83 lol nice thanks translating  \n",
       "\n",
       "[910 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2214f22a",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0c48b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09dff576",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_text'].tolist()\n",
    "y = df['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f1110b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7de5f3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train Shape : 728, y_Train Shape : 728\n",
      "X_test Shape : 182, y_test Shape :182\n"
     ]
    }
   ],
   "source": [
    "print(f'X_Train Shape : {len(X_train)}, y_Train Shape : {len(y_train)}')\n",
    "print(f'X_test Shape : {len(X_test)}, y_test Shape :{len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28ecb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b614b",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d8aea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "999a0d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'positive', 'positive', 'positive']\n"
     ]
    }
   ],
   "source": [
    "print(y_train) # its a list, but One hot expect 2D array, so conversion requires- firs need to convert into 'Numpy' array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bfa1814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert into numpy array - when converted into numpy, it automatically being a 1D array, but still need 2D array, use reshape\n",
    "y_array = np.array(y_train)\n",
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5564798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 2D conversion Done\n",
    "onehot_encoded_sparse = encoder.fit_transform(y_array.reshape(-1, 1)) # fit is learing algo, 1: Positive, 0: Negative\n",
    "print(onehot_encoded_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa492427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b01d256d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sparse : True\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#encoder = OneHotEncoder(sparse=True)\n",
    "#encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2c73d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 1)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 0)\t1.0\n",
      "  (12, 0)\t1.0\n",
      "  (13, 1)\t1.0\n",
      "  (14, 1)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (16, 1)\t1.0\n",
      "  (17, 1)\t1.0\n",
      "  (18, 1)\t1.0\n",
      "  (19, 0)\t1.0\n",
      "  (20, 0)\t1.0\n",
      "  (21, 0)\t1.0\n",
      "  (22, 0)\t1.0\n",
      "  (23, 0)\t1.0\n",
      "  (24, 1)\t1.0\n",
      "  :\t:\n",
      "  (703, 1)\t1.0\n",
      "  (704, 0)\t1.0\n",
      "  (705, 0)\t1.0\n",
      "  (706, 1)\t1.0\n",
      "  (707, 1)\t1.0\n",
      "  (708, 1)\t1.0\n",
      "  (709, 0)\t1.0\n",
      "  (710, 0)\t1.0\n",
      "  (711, 1)\t1.0\n",
      "  (712, 1)\t1.0\n",
      "  (713, 0)\t1.0\n",
      "  (714, 1)\t1.0\n",
      "  (715, 1)\t1.0\n",
      "  (716, 1)\t1.0\n",
      "  (717, 0)\t1.0\n",
      "  (718, 1)\t1.0\n",
      "  (719, 0)\t1.0\n",
      "  (720, 0)\t1.0\n",
      "  (721, 1)\t1.0\n",
      "  (722, 1)\t1.0\n",
      "  (723, 1)\t1.0\n",
      "  (724, 0)\t1.0\n",
      "  (725, 1)\t1.0\n",
      "  (726, 1)\t1.0\n",
      "  (727, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# Sparse True look like this (row, col)- sparse False when you no need to see index of row, col like (0,1, 1,1 etc)\n",
    "#onehot_encoded_sparse = encoder.fit_transform(y_array.reshape(-1, 1)) # fit is learing algo, 1: Positive, 0: Negative\n",
    "#print(onehot_encoded_sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae25e0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nonehot_encoded_sparse = encoder.fit_transform(y_train.reshape(-1, 1))-- will return error! (list has not reshape attribute )\\nYou need make y_train as 2D manually or need to do by numpy\\nReshape available in Numpy, that why need to convert list into numpy\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "onehot_encoded_sparse = encoder.fit_transform(y_train.reshape(-1, 1))-- will return error! (list has not reshape attribute )\n",
    "You need make y_train as 2D manually or need to do by numpy\n",
    "Reshape available in Numpy, that why need to convert list into numpy\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fdbd3b",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a23fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "cv = vectorizer.fit_transform(X_train)  # This vectorizer expect 1D list- reshaped not needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8d0f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2112)\t1\n",
      "  (0, 1345)\t1\n",
      "  (0, 775)\t1\n",
      "  (0, 821)\t1\n",
      "  (1, 2206)\t1\n",
      "  (1, 1000)\t1\n",
      "  (1, 2118)\t1\n",
      "  (1, 1771)\t1\n",
      "  (1, 585)\t1\n",
      "  (1, 2096)\t1\n",
      "  (1, 1190)\t1\n",
      "  (1, 751)\t1\n",
      "  (1, 69)\t1\n",
      "  (1, 2204)\t1\n",
      "  (1, 744)\t1\n",
      "  (1, 1373)\t1\n",
      "  (2, 1706)\t1\n",
      "  (2, 2742)\t1\n",
      "  (2, 175)\t1\n",
      "  (2, 265)\t1\n",
      "  (2, 2528)\t1\n",
      "  (2, 2025)\t1\n",
      "  (2, 1338)\t1\n",
      "  (2, 1211)\t1\n",
      "  (2, 969)\t1\n",
      "  :\t:\n",
      "  (726, 962)\t1\n",
      "  (726, 2470)\t1\n",
      "  (726, 2017)\t1\n",
      "  (726, 2429)\t1\n",
      "  (726, 935)\t1\n",
      "  (726, 2733)\t1\n",
      "  (726, 1366)\t1\n",
      "  (726, 1718)\t1\n",
      "  (726, 2601)\t1\n",
      "  (726, 2134)\t1\n",
      "  (727, 585)\t1\n",
      "  (727, 2470)\t1\n",
      "  (727, 1104)\t1\n",
      "  (727, 1462)\t1\n",
      "  (727, 2358)\t1\n",
      "  (727, 946)\t1\n",
      "  (727, 872)\t1\n",
      "  (727, 235)\t1\n",
      "  (727, 793)\t1\n",
      "  (727, 348)\t1\n",
      "  (727, 2493)\t1\n",
      "  (727, 1001)\t1\n",
      "  (727, 59)\t1\n",
      "  (727, 576)\t1\n",
      "  (727, 2767)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cv) # default it will shows as sparse matrix, but you can see by dense array form too, see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2801c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Showing by dense array\n",
    "print(cv.toarray()) # This will return the dense represeantion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7aa94b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0g' '10' '100000' ... '½re' '½s' '½tieï']\n"
     ]
    }
   ],
   "source": [
    " print(vectorizer.get_feature_names_out()) # This shows the feature name(it will represnet unique feature from list/doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1eae78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8355b649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef2abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a756bdb7",
   "metadata": {},
   "source": [
    "<h2 style=\"color:purple\" align=\"left\"> Working </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ed8d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder(sparse=False) : false mean the output will be in array form, False will show actual 0 & 1 \n",
    "# OneHotEncoder(sparse=True) : It mean the output will be in matrix form or dense matrix form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a65a49",
   "metadata": {},
   "source": [
    "#### OneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2337527",
   "metadata": {},
   "source": [
    "- It generally expect 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302501a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
